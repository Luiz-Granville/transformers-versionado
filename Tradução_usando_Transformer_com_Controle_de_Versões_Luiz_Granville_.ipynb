{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCg3ElKBUSBb"
      },
      "source": [
        "\n",
        "\n",
        "# Atividade de Tradução Português-Inglês com Transformer e Controle de Versões\n",
        "\n",
        "Este Colab tem como objetivo praticar a criação e o treinamento de um modelo Transformer de **sequência para sequência** para traduzir do **português para o inglês**, com a adição de **controle de versões** para acompanhamento do progresso do projeto.\n",
        "\n",
        "O **Transformer**, originalmente proposto no artigo [\"Attention is All You Need\"](https://arxiv.org/abs/1706.03762) por Vaswani et al. (2017), utiliza o mecanismo de **autoatenção**, permitindo que informações fluam eficientemente entre as sequências de entrada. Ele substitui arquiteturas mais tradicionais como **CNNs** e **RNNs**, mostrando desempenho superior em tarefas de tradução automática.\n",
        "\n",
        "## Objetivos:\n",
        "\n",
        "- Preparar um dataset de tradução (português-inglês) para treinar o modelo.\n",
        "- Implementar componentes essenciais do Transformer:\n",
        "  - Embeddings posicionais.\n",
        "  - Camadas de atenção.\n",
        "  - Codificador e decodificador.\n",
        "- Treinar o Transformer.\n",
        "- Avaliar a qualidade das traduções geradas.\n",
        "- Realizar **controle de versões** para rastrear o progresso, testes e melhorias do modelo.\n",
        "\n",
        "## Ferramentas e Tecnologias:\n",
        "\n",
        "- **TensorFlow/Keras**: para a implementação e treinamento do modelo Transformer.\n",
        "- **Git**: para o controle de versões, onde serão registrados commits que documentam o progresso e as alterações feitas.\n",
        "- **Colab**: para execução do código em ambiente interativo e compartilhável.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo1P7AN4lzdi"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/apply_the_transformer_to_machine_translation.gif\" alt=\"Aplicando o Transformer à tradução automática\">\n",
        "\n",
        "**Figura 1**: Aplicando o Transformer à tradução automática. Fonte: [Google AI Blog](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swymtxpl7W7w"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfV1batAwq9j"
      },
      "source": [
        "Instalando o [TensorFlow Datasets](https://tensorflow.org/datasets) para carregar o conjunto de dados e o [TensorFlow Text](https://www.tensorflow.org/text) para o pré-processamento de texto:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFG0NDRu5mYQ"
      },
      "outputs": [],
      "source": [
        "# Install the most re version of TensorFlow to use the improved\n",
        "# masking support for `tf.keras.layers.MultiHeadAttention`.\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n",
        "!pip uninstall -y -q tensorflow keras tensorflow-estimator tensorflow-text\n",
        "!pip install protobuf~=3.20.3\n",
        "!pip install -q tensorflow_datasets\n",
        "!pip install -q -U tensorflow-text tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GYpLBSjxJmG"
      },
      "source": [
        "Importe os módulos necessários:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjJJyJTZYebt"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf_WUi2HLhzf"
      },
      "source": [
        "## Manipulação de Dados\n",
        "\n",
        "Esta seção faz o download do conjunto de dados e do tokenizador de subpalavras, a partir [deste tutorial](https://www.tensorflow.org/text/guide/subwords_tokenizer), e depois organiza tudo em um `tf.data.Dataset` para o treinamento.\n",
        "\n",
        "<section class=\"expandable tfo-display-only-on-site\">\n",
        "<button type=\"button\" class=\"button-red button expand-control\">Alternar seção</button>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cCvXbPkccV1"
      },
      "source": [
        "### Download do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTEVgBxklzdq"
      },
      "source": [
        "Usamos o TensorFlow Datasets para carregar o [conjunto de dados de tradução Português-Inglês](https://www.tensorflow.org/datasets/catalog/ted_hrlr_translate#ted_hrlr_translatept_to_en) do TED Talks Open Translation Project. Esse conjunto de dados contém aproximadamente 52.000 exemplos de treino, 1.200 para validação e 1.800 exemplos de teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8q9t4FmN96eN"
      },
      "outputs": [],
      "source": [
        "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en',\n",
        "                               with_info=True,\n",
        "                               as_supervised=True)\n",
        "\n",
        "train_examples, val_examples = examples['train'], examples['validation']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZA4cw7F_DmSt"
      },
      "source": [
        "O objeto `tf.data.Dataset` retornado pelo TensorFlow Datasets gera pares de exemplos de texto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZFAMZJyDrFn"
      },
      "outputs": [],
      "source": [
        "for pt_examples, en_examples in train_examples.batch(3).take(1):\n",
        "  print('> Exemplos em Português:')\n",
        "  for pt in pt_examples.numpy():\n",
        "    print(pt.decode('utf-8'))\n",
        "  print()\n",
        "\n",
        "  print('> Exemplos em Inglês:')\n",
        "  for en in en_examples.numpy():\n",
        "    print(en.decode('utf-8'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJxTd6aVnZyh"
      },
      "source": [
        "### Configurar o tokenizador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mopr6oKUlzds"
      },
      "source": [
        "Agora que carregamos o conjunto de dados, precisamos tokenizar o texto, de forma que cada elemento seja representado como um [token](https://developers.google.com/machine-learning/glossary#token) ou ID de token (uma representação numérica).\n",
        "\n",
        "A tokenização é o processo de dividir o texto em \"tokens\". Dependendo do tokenizador, esses tokens podem representar pedaços de sentenças, palavras, subpalavras ou caracteres. Para saber mais sobre tokenização, visitamos [este guia](https://www.tensorflow.org/text/guide/tokenizers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QToMl0NanZPr"
      },
      "outputs": [],
      "source": [
        "model_name = 'ted_hrlr_translate_pt_en_converter'\n",
        "tf.keras.utils.get_file(\n",
        "    f'{model_name}.zip',\n",
        "    f'https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip',\n",
        "    cache_dir='.', cache_subdir='', extract=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5dbGnPXnuI1"
      },
      "outputs": [],
      "source": [
        "tokenizers = tf.saved_model.load(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-PCJijfcZ9_"
      },
      "outputs": [],
      "source": [
        "[item for item in dir(tokenizers.en) if not item.startswith('_')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_gPC5iwFXfU"
      },
      "outputs": [],
      "source": [
        "print('> This is a batch of strings:')\n",
        "for en in en_examples.numpy():\n",
        "  print(en.decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSkM7z8JFaVO"
      },
      "outputs": [],
      "source": [
        "encoded = tokenizers.en.tokenize(en_examples)\n",
        "\n",
        "print('> This is a padded-batch of token IDs:')\n",
        "for row in encoded.to_list():\n",
        "  print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CFS5aAxFdpP"
      },
      "outputs": [],
      "source": [
        "round_trip = tokenizers.en.detokenize(encoded)\n",
        "\n",
        "print('> This is human-readable text:')\n",
        "for line in round_trip.numpy():\n",
        "  print(line.decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaCeOnswVAhI"
      },
      "outputs": [],
      "source": [
        "print('> This is the text split into tokens:')\n",
        "tokens = tokenizers.en.lookup(encoded)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR3vZJf1Yhg_"
      },
      "source": [
        "A saída demonstra o aspecto de \"subpalavra\" da tokenização de subpalavras.\n",
        "\n",
        "Por exemplo, a palavra `'searchability'` é decomposta em `'search'` e `'##ability'`, enquanto a palavra `'serendipity'` é decomposta em `'s'`, `'##ere'`, `'##nd'`, `'##ip'` e `'##ity'`.\n",
        "\n",
        "Observe que o texto tokenizado inclui os tokens `'[START]'` e `'[END]'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRbke-iaaHFI"
      },
      "outputs": [],
      "source": [
        "lengths = []\n",
        "\n",
        "for pt_examples, en_examples in train_examples.batch(1024):\n",
        "  pt_tokens = tokenizers.pt.tokenize(pt_examples)\n",
        "  lengths.append(pt_tokens.row_lengths())\n",
        "\n",
        "  en_tokens = tokenizers.en.tokenize(en_examples)\n",
        "  lengths.append(en_tokens.row_lengths())\n",
        "  print('.', end='', flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ucA1q3GaK_n"
      },
      "outputs": [],
      "source": [
        "all_lengths = np.concatenate(lengths)\n",
        "\n",
        "plt.hist(all_lengths, np.linspace(0, 500, 101))\n",
        "plt.ylim(plt.ylim())\n",
        "max_length = max(all_lengths)\n",
        "plt.plot([max_length, max_length], plt.ylim())\n",
        "plt.title(f'Maximum tokens per example: {max_length}');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Yb35sTJcZq9"
      },
      "source": [
        "### Configurar um pipeline de dados com `tf.data`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZHsns5obJhN"
      },
      "source": [
        "A seguinte função recebe lotes de texto como entrada e os converte para um formato adequado para treinamento.\n",
        "\n",
        "1. Ela tokeniza os textos em lotes irregulares.\n",
        "2. Ela corta cada um para não ter mais do que `MAX_TOKENS`.\n",
        "3. Ela separa os tokens de destino (inglês) em entradas e rótulos, deslocando-os uma etapa para que, em cada posição de entrada, o `rótulo` seja o ID do próximo token.\n",
        "4. Ela converte os `RaggedTensor`s em `Tensor`s densos com preenchimento.\n",
        "5. Ela retorna um par `(entradas, rótulos)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6shgzEck3FiV"
      },
      "outputs": [],
      "source": [
        "MAX_TOKENS=64\n",
        "def prepare_batch(pt, en):\n",
        "    pt = tokenizers.pt.tokenize(pt)      # Output is ragged.\n",
        "    pt = pt[:, :MAX_TOKENS]    # Trim to MAX_TOKENS.\n",
        "    pt = pt.to_tensor()  # Convert to 0-padded dense Tensor\n",
        "\n",
        "    en = tokenizers.en.tokenize(en)\n",
        "    en = en[:, :(MAX_TOKENS+1)]\n",
        "    en_inputs = en[:, :-1].to_tensor()  # Drop the [END] tokens\n",
        "    en_labels = en[:, 1:].to_tensor()   # Drop the [START] tokens\n",
        "\n",
        "    return (pt, en_inputs), en_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAroQ6xelzdx"
      },
      "source": [
        "A função abaixo converte um conjunto de dados de exemplos de texto em dados em lotes para treinamento.\n",
        "\n",
        "1. Ela tokeniza o texto e filtra as sequências que são muito longas.  \n",
        "   (O uso de `batch`/`unbatch` é incluído porque o tokenizador é muito mais eficiente em grandes lotes).\n",
        "2. O método `cache` garante que esse trabalho seja executado apenas uma vez.\n",
        "3. Em seguida, `shuffle` e `dense_to_ragged_batch` randomizam a ordem e montam lotes de exemplos.\n",
        "4. Por fim, `prefetch` executa o conjunto de dados em paralelo com o modelo para garantir que os dados estejam disponíveis quando necessário. Veja [Melhores desempenhos com o `tf.data`](https://www.tensorflow.org/guide/data_performance.ipynb) para mais detalhes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcRp7VcQ5m6g"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUN_jLBTwNxk"
      },
      "outputs": [],
      "source": [
        "def make_batches(ds):\n",
        "  return (\n",
        "      ds\n",
        "      .shuffle(BUFFER_SIZE)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .map(prepare_batch, tf.data.AUTOTUNE)\n",
        "      .prefetch(buffer_size=tf.data.AUTOTUNE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX_h3tCnwgR4"
      },
      "source": [
        " </section>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itSWqk-ivrRg"
      },
      "source": [
        "## Dataset de Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSswr5TKvoNM"
      },
      "outputs": [],
      "source": [
        "# Create training and validation set batches.\n",
        "train_batches = make_batches(train_examples)\n",
        "val_batches = make_batches(val_examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAw2XjRwLFWr"
      },
      "outputs": [],
      "source": [
        "for (pt, en), en_labels in train_batches.take(1):\n",
        "  break\n",
        "\n",
        "print(pt.shape)\n",
        "print(en.shape)\n",
        "print(en_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzo3JKaqx46g"
      },
      "source": [
        "The `en` and `en_labels` are the same, just shifted by 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apFeC-WWxzR4"
      },
      "outputs": [],
      "source": [
        "print(en[0][:10])\n",
        "print(en_labels[0][:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e7hKcxn6-zd"
      },
      "source": [
        "## Definir os componentes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Rz82wEs5biZ"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(length, depth):\n",
        "  depth = depth/2\n",
        "\n",
        "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
        "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
        "\n",
        "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
        "  angle_rads = positions * angle_rates      # (pos, depth)\n",
        "\n",
        "  pos_encoding = np.concatenate(\n",
        "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "      axis=-1)\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKf4Ky2dhg0L"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "pos_encoding = positional_encoding(length=2048, depth=512)\n",
        "\n",
        "# Check the shape.\n",
        "print(pos_encoding.shape)\n",
        "\n",
        "# Plot the dimensions.\n",
        "plt.pcolormesh(pos_encoding.numpy().T, cmap='RdBu')\n",
        "plt.ylabel('Depth')\n",
        "plt.xlabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKqVkl9Jlzg6"
      },
      "source": [
        "Por definição, esses vetores se alinham bem com vetores próximos ao longo do eixo de posição. Abaixo, os vetores de codificação de posição são normalizados, e o vetor da posição `1000` é comparado, por meio do produto escalar, a todos os outros:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXY-8_uEhcRD"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "pos_encoding/=tf.norm(pos_encoding, axis=1, keepdims=True)\n",
        "p = pos_encoding[1000]\n",
        "dots = tf.einsum('pd,d -> p', pos_encoding, p)\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(dots)\n",
        "plt.ylim([0,1])\n",
        "plt.plot([950, 950, float('nan'), 1050, 1050],\n",
        "         [0,1,float('nan'),0,1], color='k', label='Zoom')\n",
        "plt.legend()\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(dots)\n",
        "plt.xlim([950, 1050])\n",
        "plt.ylim([0,1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "838tmM1cm9cB"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "  def __init__(self, vocab_size, d_model):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
        "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
        "\n",
        "  def compute_mask(self, *args, **kwargs):\n",
        "    return self.embedding.compute_mask(*args, **kwargs)\n",
        "\n",
        "  def call(self, x):\n",
        "    length = tf.shape(x)[1]\n",
        "    x = self.embedding(x)\n",
        "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfz-EaCEDfUJ"
      },
      "outputs": [],
      "source": [
        "embed_pt = PositionalEmbedding(vocab_size=tokenizers.pt.get_vocab_size().numpy(), d_model=248)\n",
        "embed_en = PositionalEmbedding(vocab_size=tokenizers.en.get_vocab_size().numpy(), d_model=248)\n",
        "\n",
        "pt_emb = embed_pt(pt)\n",
        "en_emb = embed_en(en)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fJZ_ArLELhJ"
      },
      "outputs": [],
      "source": [
        "en_emb._keras_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE9cEBWCMKOP"
      },
      "source": [
        "### Adicionar e normalizar\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "  <th colspan=2>Adicionar e normalizar</th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/Add+Norm.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tMGOGki35KI"
      },
      "source": [
        "### A camada de atenção básica\n",
        "\n",
        "Camadas de atenção são usadas em todo o modelo. Todas são idênticas, exceto pela configuração da atenção. Cada uma contém uma `layers.MultiHeadAttention`, uma `layers.LayerNormalization` e uma `layers.Add`.\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "  <th colspan=2>A camada de atenção básica</th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/BaseAttention.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VLa5QcdPpv5"
      },
      "outputs": [],
      "source": [
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfHVbJUWv8qp"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(BaseAttention):\n",
        "  def call(self, x, context):\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query=x,\n",
        "        key=context,\n",
        "        value=context,\n",
        "        return_attention_scores=True)\n",
        "\n",
        "    # Cache the attention scores for plotting later.\n",
        "    self.last_attn_scores = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qw1FJV5qRk79"
      },
      "outputs": [],
      "source": [
        "sample_ca = CrossAttention(num_heads=2, key_dim=248)\n",
        "\n",
        "print(pt_emb.shape)\n",
        "print(en_emb.shape)\n",
        "print(sample_ca(en_emb, pt_emb).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNqoTpn1wB3i"
      },
      "outputs": [],
      "source": [
        "class GlobalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPn2D07-Jcmj"
      },
      "outputs": [],
      "source": [
        "sample_gsa = GlobalSelfAttention(num_heads=2, key_dim=248)\n",
        "\n",
        "print(pt_emb.shape)\n",
        "print(sample_gsa(pt_emb).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd-ga2tQfzhE"
      },
      "source": [
        "Sticking with the same style as before you could draw it like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MMQ-AfKD99_"
      },
      "outputs": [],
      "source": [
        "class CausalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x,\n",
        "        use_causal_mask = True)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4dQuzvlD99_"
      },
      "outputs": [],
      "source": [
        "sample_csa = CausalSelfAttention(num_heads=2, key_dim=248)\n",
        "\n",
        "print(en_emb.shape)\n",
        "print(sample_csa(en_emb).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwKlheQ-WVxl"
      },
      "outputs": [],
      "source": [
        "out1 = sample_csa(embed_en(en[:, :3]))\n",
        "out2 = sample_csa(embed_en(en))[:, :3]\n",
        "\n",
        "tf.reduce_max(abs(out1 - out2)).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLjScSWQv9M5"
      },
      "source": [
        "### A rede neural de feedforward\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "  <th colspan=1>A rede neural de feedforward</th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/FeedForward.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "A rede consiste em duas camadas lineares (`tf.keras.layers.Dense`) com uma ativação ReLU entre elas e uma camada de dropout. Assim como nas camadas de atenção, o código aqui também inclui a conexão residual e a normalização:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAYLeu0uwXYK"
      },
      "outputs": [],
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.seq = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),\n",
        "      tf.keras.layers.Dense(d_model),\n",
        "      tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "    self.add = tf.keras.layers.Add()\n",
        "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.add([x, self.seq(x)])\n",
        "    x = self.layer_norm(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-Y8Yqi1_hUt"
      },
      "outputs": [],
      "source": [
        "sample_ffn = FeedForward(248, 248)\n",
        "\n",
        "print(en_emb.shape)\n",
        "print(sample_ffn(en_emb).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o-AXGAPt6ZC"
      },
      "source": [
        "### O codificador\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "  <th colspan=1>O codificador</th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/Encoder.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "O codificador consiste em:\n",
        "\n",
        "- Uma camada `PositionalEmbedding` na entrada.\n",
        "- Um conjunto de camadas `EncoderLayer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncyS-Ms3i2x_"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.self_attention = GlobalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.self_attention(x)\n",
        "    x = self.ffn(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeXHMUlb6q6F"
      },
      "source": [
        "And a quick test, the output will have the same shape as the input:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzZRXdO0mI48"
      },
      "outputs": [],
      "source": [
        "sample_encoder_layer = EncoderLayer(d_model=248, num_heads=4, dff=248)\n",
        "\n",
        "print(pt_emb.shape)\n",
        "print(sample_encoder_layer(pt_emb).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE1H51Ajm0q1"
      },
      "source": [
        "### O codificador\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "  <th colspan=1>O codificador</th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/Encoder.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "O codificador consiste em:\n",
        "\n",
        "- Uma camada `PositionalEmbedding` na entrada.\n",
        "- Um conjunto de camadas `EncoderLayer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpEox7gJ8FCI"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads,\n",
        "               dff, vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(\n",
        "        vocab_size=vocab_size, d_model=d_model)\n",
        "\n",
        "    self.enc_layers = [\n",
        "        EncoderLayer(d_model=d_model,\n",
        "                     num_heads=num_heads,\n",
        "                     dff=dff,\n",
        "                     dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x):\n",
        "    # `x` is token-IDs shape: (batch, seq_len)\n",
        "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "\n",
        "    # Add dropout.\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x)\n",
        "\n",
        "    return x  # Shape `(batch_size, seq_len, d_model)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDPXTvYgJH8s"
      },
      "outputs": [],
      "source": [
        "# Instantiate the encoder.\n",
        "sample_encoder = Encoder(num_layers=2,\n",
        "                         d_model=248,\n",
        "                         num_heads=4,\n",
        "                         dff=248,\n",
        "                         vocab_size=8500)\n",
        "\n",
        "sample_encoder_output = sample_encoder(pt, training=False)\n",
        "\n",
        "# Print the shape.\n",
        "print(pt.shape)\n",
        "print(sample_encoder_output.shape)  # Shape `(batch_size, input_seq_len, d_model)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LO_48Owmx_o"
      },
      "source": [
        "### A camada do decodificador\n",
        "\n",
        "A pilha do decodificador é um pouco mais complexa, com cada `DecoderLayer` contendo uma `CausalSelfAttention`, uma `CrossAttention` e uma camada `FeedForward`:\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "  <th colspan=1>A camada do decodificador</th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/DecoderLayer.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SoX0-vd1hue"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,\n",
        "               *,\n",
        "               d_model,\n",
        "               num_heads,\n",
        "               dff,\n",
        "               dropout_rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.causal_self_attention = CausalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.cross_attention = CrossAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x, context):\n",
        "    x = self.causal_self_attention(x=x)\n",
        "    x = self.cross_attention(x=x, context=context)\n",
        "\n",
        "    # Cache the last attention scores for plotting later\n",
        "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
        "\n",
        "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ne2Bqx8k71l0"
      },
      "outputs": [],
      "source": [
        "sample_decoder_layer = DecoderLayer(d_model=248, num_heads=4, dff=248)\n",
        "\n",
        "sample_decoder_layer_output = sample_decoder_layer(\n",
        "    x=en_emb, context=pt_emb)\n",
        "\n",
        "print(en_emb.shape)\n",
        "print(pt_emb.shape)\n",
        "print(sample_decoder_layer_output.shape)  # `(batch_size, seq_len, d_model)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-uO6ls8m2O5"
      },
      "source": [
        "### O decodificador\n",
        "\n",
        "Assim como o `Encoder`, o `Decoder` consiste em uma `PositionalEmbedding` e uma pilha de `DecoderLayer`s:\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "  <th colspan=1>A camada de embedding e codificação posicional</th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/Decoder.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5_d5-PLQXwY"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
        "               dropout_rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
        "                                             d_model=d_model)\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "    self.dec_layers = [\n",
        "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
        "                     dff=dff, dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "\n",
        "    self.last_attn_scores = None\n",
        "\n",
        "  def call(self, x, context):\n",
        "    # `x` is token-IDs shape (batch, target_seq_len)\n",
        "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x  = self.dec_layers[i](x, context)\n",
        "\n",
        "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
        "\n",
        "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyHdG_jWPgKu"
      },
      "outputs": [],
      "source": [
        "# Instantiate the decoder.\n",
        "sample_decoder = Decoder(num_layers=2,\n",
        "                         d_model=248,\n",
        "                         num_heads=4,\n",
        "                         dff=248,\n",
        "                         vocab_size=8000)\n",
        "\n",
        "output = sample_decoder(\n",
        "    x=en,\n",
        "    context=pt_emb)\n",
        "\n",
        "# Print the shapes.\n",
        "print(en.shape)\n",
        "print(pt_emb.shape)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioJ4XJAUAReI"
      },
      "outputs": [],
      "source": [
        "sample_decoder.last_attn_scores.shape  # (batch, heads, target_seq, input_seq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y54xnJnuYgJ7"
      },
      "source": [
        "## O Transformer\n",
        "\n",
        "Agora que você tem o `Encoder` e o `Decoder`, para completar o modelo `Transformer`, é necessário juntá-los e adicionar uma camada linear (`Dense`) final que converte o vetor resultante em cada localização em probabilidades de tokens de saída.\n",
        "\n",
        "A saída do decodificador é a entrada para essa camada linear final.\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "  <th colspan=1>O transformer</th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PED3bIpOYkBu"
      },
      "outputs": [],
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
        "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=input_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=target_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
        "    # first argument.\n",
        "    context, x  = inputs\n",
        "\n",
        "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
        "\n",
        "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
        "\n",
        "    # Final linear layer output.\n",
        "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
        "\n",
        "    try:\n",
        "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
        "      # b/250038731\n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    # Return the final output and the attention weights.\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsINyf1VEQLC"
      },
      "source": [
        "### Hiperparâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzyo6KDfVyhl"
      },
      "outputs": [],
      "source": [
        "num_layers = 4\n",
        "d_model = 124\n",
        "dff = 248\n",
        "num_heads = 4\n",
        "dropout_rate = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g08YOE-zHRqY"
      },
      "source": [
        "### Instanciando Tranformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiysUa--4tOU"
      },
      "outputs": [],
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=tokenizers.pt.get_vocab_size().numpy(),\n",
        "    target_vocab_size=tokenizers.en.get_vocab_size().numpy(),\n",
        "    dropout_rate=dropout_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8eO85hpFHmE"
      },
      "outputs": [],
      "source": [
        "output = transformer((pt, en))\n",
        "\n",
        "print(en.shape)\n",
        "print(pt.shape)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olTLrK8pAcLd"
      },
      "outputs": [],
      "source": [
        "attn_scores = transformer.decoder.dec_layers[-1].last_attn_scores\n",
        "print(attn_scores.shape)  # (batch, heads, target_seq, input_seq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfoBfC2oQtEy"
      },
      "source": [
        "## Treino\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYEGhEOtzn5W"
      },
      "source": [
        "### Setar otimizador\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYQdOO1axwEI"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, dtype=tf.float32)\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7r4scdulztRx"
      },
      "outputs": [],
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xij3MwYVRAAS"
      },
      "outputs": [],
      "source": [
        "plt.plot(learning_rate(tf.range(40000, dtype=tf.float32)))\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.xlabel('Train Step')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgkDE7hzo8r5"
      },
      "source": [
        "### Função de perda e métricas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67oqVHiT0Eiu"
      },
      "outputs": [],
      "source": [
        "def masked_loss(label, pred):\n",
        "  mask = label != 0\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "  loss = loss_object(label, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "  return loss\n",
        "\n",
        "\n",
        "def masked_accuracy(label, pred):\n",
        "  pred = tf.argmax(pred, axis=2)\n",
        "  label = tf.cast(label, pred.dtype)\n",
        "  match = label == pred\n",
        "\n",
        "  mask = label != 0\n",
        "\n",
        "  match = match & mask\n",
        "\n",
        "  match = tf.cast(match, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYEasEOsdn5W"
      },
      "source": [
        "### Treinando"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Una1v0hDlIsT"
      },
      "outputs": [],
      "source": [
        "transformer.compile(\n",
        "    loss=masked_loss,\n",
        "    optimizer=optimizer,\n",
        "    metrics=[masked_accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jg35qKvVlctp"
      },
      "outputs": [],
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "transformer.fit(train_batches,\n",
        "                epochs=10,\n",
        "                validation_data=val_batches,\n",
        "                callbacks=[early_stopping])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
